{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Holzweber_11803108_FER_FER2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fz4nScbBqib"
      },
      "source": [
        "# Facial Expression Recognition - Using FER2013 Database\n",
        "**Author**: Christopher Holzweber\n",
        "\n",
        "**Institution**: Johannes Kepler Universit√§t Linz - Institute of Computational Perception\n",
        "\n",
        "**Intention**: Bachelorthesis - Prototype for FER\n",
        "\n",
        "**Description**: \n",
        "In this Notebook File a CNN Model is trained using the FER2013 Dataset. Here two strategies are used:\n",
        "\n",
        "# 1: Training Model from Scratch with original Data, augmentation + histogram equalization.\n",
        "\n",
        "This CNN Architekture is based on the paper\n",
        "\n",
        "Facial Emotion Recognition Using Deep Convolutional Neural Network by \n",
        "\n",
        "Pranav E.\n",
        "School of Engineering\n",
        "Cochin University of Science\n",
        "and Technology\n",
        "Kochi, India\n",
        "\n",
        "Suraj Kamal\n",
        "Department of Electronics\n",
        "Cochin University of Science and\n",
        "Technology\n",
        "Kochi, India\n",
        "\n",
        "Satheesh Chandran C.\n",
        "Department of Electronics\n",
        "Cochin University of Science and\n",
        "Technology\n",
        "Kochi, India\n",
        "\n",
        "Supriya M.H.\n",
        "Department of Electronics\n",
        "Cochin University of Science\n",
        "and Technology\n",
        "Kochi, India\n",
        "\n",
        "Latest Results: loss: 0.9818 - accuracy: 0.6344 - val_loss: 1.1073 - val_accuracy: 0.5913\n",
        "\n",
        "You can see, that the model is slightly overfitting for the untouched data\n",
        "\n",
        "\n",
        "# 2: Training Model from Scratch with original Data + Augmented Data and histogram equalization. \n",
        "\n",
        "This model is a much deeper then the first approach. It is based on the paper\n",
        "\n",
        "*Facial Expression Recognition using Convolutional Neural Networks: State of the Art \n",
        "\n",
        "by Christopher Pramerdorfer, Martin Kampel\n",
        "Computer Vision Lab, TU Wien, Vienna, Austria*\n",
        "\n",
        "Therefore this Model will train much longer, since there is more data to process.\n",
        "\n",
        "latest results on accuracy: accuracy: 0.6529 - val_loss: 1.1525 - val_accuracy: 0.5705\n",
        "\n",
        "**Required Installations**:\n",
        "\n",
        "Tensorflow: pip install tensorflow\n",
        "\n",
        "Numpy: pip install numpy\n",
        "\n",
        "OpenCV: pip install opencv-python\n",
        "\n",
        "Matplotlib: python -m pip install -U matplotlib\n",
        "\n",
        "Pandas: pip install pandas\n",
        "\n",
        "Seaborn: pip install seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxrBcGofAMWv"
      },
      "source": [
        "# %tensorflow_version 2.x  # making sure using version 2 of tensorflow\n",
        "import tensorflow as tf  # import tensorflow module\n",
        "import numpy as np # standard lib. for calculations\n",
        "import cv2  # library for imagehandling \n",
        "import matplotlib.pyplot as plt  # plotting images\n",
        "import os  # for file handling and loading\n",
        "import pandas as pd\n",
        "import random # for datashuffling\n",
        "from sklearn.metrics import confusion_matrix, plot_roc_curve # for evaluationg the CNN Models\n",
        "import seaborn as sn # pi install seaborn - used for plotting confusion matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xox5x2UMGJZd"
      },
      "source": [
        "# Dataset\n",
        "For this model the dataset FER2013 is used\n",
        "\n",
        "https://www.kaggle.com/msambare/fer2013\n",
        "\n",
        "The data is already seperated into a test and a train dataset.\n",
        "\n",
        "The FER2013 set classifies facial emotions into 7 Categories:\n",
        "\n",
        "(0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsbT1TXhvZyV"
      },
      "source": [
        " # !unzip FER2013 # if training in google colab - upload zip file of FER2013 and unzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f51JDh_HfKoo"
      },
      "source": [
        "**Define Classes and Data/Label Arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R23zggrGQO_l"
      },
      "source": [
        "emotion_classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "IMG_SIZE = 48 #set pixel size of image, images are used to be IMG_SIZExIMG_SIZE\n",
        "imagetype = 0 # 0 for grayscale, 1 for rgb\n",
        "train_data = [] # picture data for model training\n",
        "train_label = [] # labels of training data\n",
        "test_data = [] # picture data for model testing\n",
        "test_label = []  # labels of testing data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKmgjyDunWYn"
      },
      "source": [
        "**Read all  Images from subfolders and return data  + label tuples**\n",
        "\n",
        "The readData Method reads all Files from a given directory, consisting of Labeled Subfoldes. e.g. FER2013/0/xyz.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh41xS6xfvZz"
      },
      "source": [
        "def readData(directory,nrsubfolders):\n",
        "    dataframe = []\n",
        "    traindir = directory\n",
        "    for cs in range(0, nrsubfolders):\n",
        "        path = os.path.join(traindir,str(cs))  # Iterate over every subfolder\n",
        "        for img in os.listdir(path):\n",
        "            tempImg = cv2.imread(os.path.join(path,img),imagetype) #readImg\n",
        "            tempImg = cv2.equalizeHist(tempImg) #histogram equalization\n",
        "            tempImg = cv2.resize(tempImg, (IMG_SIZE, IMG_SIZE)) #resize to IMG_SIZE\n",
        "            dataframe.append([tempImg,cs]) #append tuple to dataframe\n",
        "    return dataframe"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oda1X5WrqzUA"
      },
      "source": [
        "**Load all training and test images - shuffle them and normalize them**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7Y4O92nqyyv"
      },
      "source": [
        "tempdata = readData(\"./FER2013/train/\",len(emotion_classes)) # read training data\n",
        "random.shuffle(tempdata) #shuffle data\n",
        "#store data in according arrays, seperating the created tuples \n",
        "for feat,label in tempdata:\n",
        "    train_data.append(feat)\n",
        "    train_label.append(label)\n",
        "tempdata = readData(\"./FER2013/test/\",len(emotion_classes)) # read testing data\n",
        "random.shuffle(tempdata) #shuffle data\n",
        "#store data in according arrays\n",
        "for feat,label in tempdata:\n",
        "    test_data.append(feat)\n",
        "    test_label.append(label)\n",
        "\n",
        "if imagetype==0: #grayscale mode\n",
        "    # create arrays out of lists\n",
        "    train_data = np.array(train_data).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
        "    train_label = np.array(train_label)\n",
        "    test_data = np.array(test_data).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
        "    test_label = np.array(test_label)\n",
        "else: #rgb mode\n",
        "    # create arrays out of lists\n",
        "    train_data = np.array(train_data)\n",
        "    train_label = np.array(train_label)\n",
        "    test_data = np.array(test_data)\n",
        "    test_label = np.array(test_label)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJPPDjpysX40"
      },
      "source": [
        "# normalize datavalues for machinelearning - best practice that values are between [0, 1]\n",
        "z = np.array(255., dtype=np.float64) #if not enough RAM is available, use float32\n",
        "train_data, test_data = train_data / z, test_data / z"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOCz-9B9ocHi"
      },
      "source": [
        "# SetUp CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBppKrQkoqRd"
      },
      "source": [
        "from tensorflow.keras import layers, models  # use models and layers given by tensorflow framework"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzSBEd0julL9"
      },
      "source": [
        "# Model Skeleton reused form the Paper Facial Emotion Recognition Using Deep Convolutional Neural Network\n",
        "if imagetype==0: #set dimension of input layer\n",
        "    dim = 1 #grayscale channels\n",
        "else:\n",
        "    dim = 3 #rgb channels\n",
        "initializer = tf.keras.initializers.HeNormal()\n",
        "model2020 = models.Sequential()\n",
        "#\n",
        "model2020.add(tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"))\n",
        "model2020.add(tf.keras.layers.experimental.preprocessing.RandomCrop(48,48))\n",
        "model2020.add(layers.Conv2D(64, (3,3), activation='relu', input_shape=(IMG_SIZE,IMG_SIZE, dim),padding = 'same', kernel_initializer=initializer))\n",
        "model2020.add(layers.MaxPooling2D((2, 2)))\n",
        "model2020.add(layers.BatchNormalization())\n",
        "model2020.add(layers.Conv2D(128, (3,3), activation='relu',padding = 'same', kernel_initializer=initializer))\n",
        "model2020.add(layers.MaxPooling2D((2, 2)))\n",
        "model2020.add(layers.BatchNormalization())\n",
        "model2020.add(layers.Conv2D(256, (3, 3), activation='relu',padding = 'same', kernel_initializer=initializer))\n",
        "model2020.add(layers.MaxPooling2D((2, 2)))\n",
        "model2020.add(layers.BatchNormalization())\n",
        "model2020.add(layers.Flatten())\n",
        "model2020.add(layers.Dropout(0.5))\n",
        "model2020.add(layers.Dense(256, activation='relu'))\n",
        "model2020.add(layers.Dense(128, activation='relu')) #added additional\n",
        "model2020.add(layers.Dense(7, activation = 'softmax'))\n",
        "#model2020.summary()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95yq8-dIqSk1"
      },
      "source": [
        "# *Training Area*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4IVi-lnulL-",
        "scrolled": true
      },
      "source": [
        "model2020.compile(optimizer='Adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model2020.fit(train_data, train_label, epochs=6, \n",
        "                    validation_data=(test_data, test_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWBL7xwMulL-"
      },
      "source": [
        "model2020.save('./SavedModels/model2020_fer2013_p48_dim1.h5')  # Save Model in Modeldirectory"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J0jdaL4aB1l"
      },
      "source": [
        "model2020.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkUMp7tUulL-"
      },
      "source": [
        "# *Testing and Validation Area of Model2020*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBDiCtpesJJp"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss,'y',label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCURH6uSOo1b"
      },
      "source": [
        "## Create Confusion Matrix of trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT_yOQtgulMA"
      },
      "source": [
        "def getConfusionMatrix(model):\n",
        "    predicted = model.predict(test_data) #prediction vektor of the loaded test_data\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    for i in range(0, len(test_label)):\n",
        "        y_true.append(emotion_classes[test_label[i]]) #create a vektor with emotion_labels\n",
        "        y_pred.append(emotion_classes[np.argmax(predicted[i,:])])\n",
        "    y_pred = np.array(y_pred) # cast both vektors to np. arrays as needed by the confusion_matrix function\n",
        "    y_true = np.array(y_true)\n",
        "    return confusion_matrix(y_true, y_pred, labels = emotion_classes, normalize='true')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gSqmbejulMB"
      },
      "source": [
        "def printConfusionMatrix(model):\n",
        "    conmatrix = getConfusionMatrix(model)\n",
        "    df_cm = pd.DataFrame(conmatrix, index = [i for i in emotion_classes],\n",
        "                  columns = [i for i in emotion_classes])\n",
        "\n",
        "    plt.figure(figsize = (10,7))\n",
        "    sn.heatmap(df_cm, annot=True, cmap=\"YlGnBu\")\n",
        "    plt.title('Confusion Matrix of CNN Model')\n",
        "    # Set x-axis label\n",
        "    plt.xlabel('Predicted')\n",
        "    # Set y-axis label\n",
        "    plt.ylabel('Actual')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoGtRgDxzXCb"
      },
      "source": [
        "model2020 = tf.keras.models.load_model('./SavedModels/model2020_fer2013_p48_dim1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5Ct5DiulMB"
      },
      "source": [
        "printConfusionMatrix(model2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVhojUovulMF"
      },
      "source": [
        "## VGG Architekture Based"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxXFTwf0ulMG"
      },
      "source": [
        "**CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPQk9_4dulMG"
      },
      "source": [
        "activation = 'relu'\n",
        "initializer = tf.keras.initializers.HeNormal()\n",
        "# Model Skeleton reused form the Paper Facial Expression Recognition using Convolutional Neural Networks: State of the Art\n",
        "model_vgg = models.Sequential()\n",
        "#\n",
        "model_vgg.add(tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"))\n",
        "model_vgg.add(tf.keras.layers.experimental.preprocessing.RandomCrop(48,48))\n",
        "#Block 1\n",
        "model_vgg.add(layers.Conv2D(64, (3,3), activation=activation, input_shape=(IMG_SIZE,IMG_SIZE, 1),padding = 'same', kernel_initializer=initializer))\n",
        "model_vgg.add(layers.BatchNormalization())\n",
        "model_vgg.add(layers.Conv2D(64, (3,3), activation=activation,padding = 'same', kernel_initializer=initializer))\n",
        "model_vgg.add(layers.BatchNormalization())\n",
        "model_vgg.add(layers.MaxPooling2D((2, 2)))\n",
        "#Block 2\n",
        "model_vgg.add(layers.Conv2D(128, (3,3), activation=activation,padding = 'same', kernel_initializer=initializer))\n",
        "model_vgg.add(layers.BatchNormalization())\n",
        "model_vgg.add(layers.Conv2D(128, (3,3), activation=activation))\n",
        "model_vgg.add(layers.BatchNormalization())\n",
        "model_vgg.add(layers.MaxPooling2D((2, 2)))\n",
        "#Block 3\n",
        "model_vgg.add(layers.Conv2D(256, (3, 3), activation=activation,padding = 'same', kernel_initializer=initializer))\n",
        "model_vgg.add(layers.BatchNormalization())\n",
        "model_vgg.add(layers.Conv2D(256, (3, 3), activation=activation,padding = 'same', kernel_initializer=initializer))\n",
        "model_vgg.add(layers.BatchNormalization())\n",
        "model_vgg.add(layers.MaxPooling2D((2, 2)))\n",
        "#Block 4\n",
        "model_vgg.add(layers.Conv2D(512, (3, 3), activation=activation,padding = 'same', kernel_initializer=initializer))\n",
        "model_vgg.add(layers.BatchNormalization())\n",
        "model_vgg.add(layers.Conv2D(512, (3, 3), activation=activation,padding = 'same', kernel_initializer=initializer))\n",
        "model_vgg.add(layers.BatchNormalization())\n",
        "model_vgg.add(layers.MaxPooling2D((2, 2)))\n",
        "#End of Convolution\n",
        "model_vgg.add(layers.Flatten())\n",
        "#Dropout after first fully connected\n",
        "model_vgg.add(layers.Dropout(0.5))\n",
        "#Backend\n",
        "model_vgg.add(layers.Dense(1024, activation='relu'))\n",
        "model_vgg.add(layers.BatchNormalization())\n",
        "model_vgg.add(layers.Dense(7, activation = 'softmax'))\n",
        "#model_vgg.summary()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzonXM90ulMH"
      },
      "source": [
        "model_vgg.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, decay = 0.0001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6N2u26mulMH",
        "scrolled": true
      },
      "source": [
        "history = model_vgg.fit(train_data, train_label, epochs=14, \n",
        "                    validation_data=(test_data, test_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzJtwRdhulMI"
      },
      "source": [
        "model_vgg.save('./SavedModels/model_vgg_fer2013_p48_dim1.h5')  # Save Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OKqULjozXCd"
      },
      "source": [
        "model_vgg = tf.keras.models.load_model('./model_vgg_fer2013_p48_dim1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IL49oqhBPDu"
      },
      "source": [
        "model_vgg.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dzfuDwpBp4N"
      },
      "source": [
        "printConfusionMatrix(model_vgg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P4xfoWpzXCd"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss,'y',label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}